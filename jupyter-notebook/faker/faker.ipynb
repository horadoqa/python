{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E ai Fake\n",
    "\n",
    "Projetos utilizando a biblioteca `faker`\n",
    "\n",
    "## Isolar o ambiente:\n",
    "\n",
    "```bash\n",
    "python3 -m venv ./venv && source venv/bin/activate\n",
    "```\n",
    "\n",
    "## Instalar Dependências\n",
    "\n",
    "```bash\n",
    "pip install faker pandas\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "## Projetos\n",
    "\n",
    "- Fake_medical.py\n",
    "fake_medical é um pacote que gera dados médicos falsos para testes e exemplos.\n",
    "\n",
    "- Fake_real_state.py\n",
    "fake_real_state é um pacote que gera dados de imóveis falsos para testes e exemplos.\n",
    "\n",
    "- Fake_user.py\n",
    "fake_user é um pacote que gera dados de usuários falsos para testes e exemplos.\n",
    "\n",
    "- Fake_videogame.py\n",
    "fake_videogame é um pacote que gera dados de videogames falsos para testes e exemplos.\n",
    "\n",
    "- Fake_retail.py\n",
    "fake_retail é um pacote que gera dados de varejo falsos para testes e exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faker in /home/rfahham/.local/lib/python3.10/site-packages (30.8.1)\n",
      "Requirement already satisfied: pandas in /home/rfahham/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: typing-extensions in /home/rfahham/.local/lib/python3.10/site-packages (from faker) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/rfahham/.local/lib/python3.10/site-packages (from faker) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/rfahham/.local/lib/python3.10/site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/rfahham/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/rfahham/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install faker pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usuários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar a biblioteca Faker para o português do Brasil\n",
    "fake = Faker('pt_BR')\n",
    "\n",
    "def generate_fake_data(n):\n",
    "    data = {\n",
    "        \"Nome\": [fake.name() for _ in range(n)],\n",
    "        \"Endereço\": [fake.address().replace(\"\\n\", \", \") for _ in range(n)],\n",
    "        \"Email\": [fake.email() for _ in range(n)],\n",
    "        \"Telefone\": [fake.phone_number() for _ in range(n)],\n",
    "        \"Data de Nascimento\": [fake.date_of_birth() for _ in range(n)],\n",
    "        \"Profissão\": [fake.job() for _ in range(n)],\n",
    "        \"Empresa\": [fake.company() for _ in range(n)],\n",
    "        \"Site\": [fake.url() for _ in range(n)],\n",
    "        \"País\": ['Brasil' for _ in range(n)]  # Como estamos usando a localização 'pt_BR', o país será fixado como Brasil.\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Gere um dataframe com 10 linhas de dados fictícios\n",
    "df = generate_fake_data(10)\n",
    "df.to_csv('faker/fake_usuario.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usuários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "nome = fake.name()\n",
    "primeiro_nome_feminino = fake.first_name_female()\n",
    "primeiro_nome_masculino = fake.first_name_male()\n",
    "usuario = fake.user_name()\n",
    "senha = fake.password()\n",
    "mes = fake.month()\n",
    "\n",
    "print(f\"Nome: {nome}\")\n",
    "print(f\"Nome feminino: {primeiro_nome_feminino}\")\n",
    "print(f\"Nome feminino: {primeiro_nome_masculino}\")\n",
    "print(f\"Usuário: {usuario}\")\n",
    "print(f\"Senha: {senha}\")\n",
    "print(f\"Mês: {mes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Configurar a biblioteca Faker\n",
    "fake = Faker()\n",
    "\n",
    "def generate_medical_data(n):\n",
    "    # Alergias, medicações e tipos sanguíneos fictícios para o dataset\n",
    "    allergies = [\"Penicilina\", \"Polén\", \"Látex\", \"Amendoim\", \"Glúten\", \"Nenhum\"]\n",
    "    medications = [\"Atorvastatina\", \"Lisinopril\", \"Metformina\", \"Sertralina\", \"Nenhum\"]\n",
    "    blood_types = [\"A+\", \"A-\", \"B+\", \"B-\", \"O+\", \"O-\", \"AB+\", \"AB-\"]\n",
    "\n",
    "    # Gerar dados fictícios\n",
    "    patient_ids = [i+1 for i in range(n)]\n",
    "    patient_names = [fake.name() for _ in range(n)]\n",
    "    birth_dates = [fake.date_of_birth(tzinfo=None, minimum_age=0, maximum_age=100) for _ in range(n)]\n",
    "    blood_types_data = [fake.random_element(elements=blood_types) for _ in range(n)]\n",
    "    heights = [fake.random_int(min=140, max=210) for _ in range(n)]\n",
    "    weights = [round(random.uniform(40.0, 120.0), 1) for _ in range(n)]\n",
    "    patient_allergies = [fake.random_element(elements=allergies) for _ in range(n)]\n",
    "    regular_medications = [fake.random_element(elements=medications) for _ in range(n)]\n",
    "    last_appointment = [fake.date_this_year(before_today=True, after_today=False) for _ in range(n)]\n",
    "    diagnosis = [fake.sentence(nb_words=5) for _ in range(n)]\n",
    "\n",
    "    # Criar DataFrame\n",
    "    data = {\n",
    "        \"ID do Paciente\": patient_ids,\n",
    "        \"Nome\": patient_names,\n",
    "        \"Data de Nascimento\": birth_dates,\n",
    "        \"Tipo Sanguíneo\": blood_types_data,\n",
    "        \"Altura (cm)\": heights,\n",
    "        \"Peso (kg)\": weights,\n",
    "        \"Alergias\": patient_allergies,\n",
    "        \"Medicação Regular\": regular_medications,\n",
    "        \"Última Consulta\": last_appointment,\n",
    "        \"Diagnóstico\": diagnosis\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Gere um dataset com 100 linhas de dados fictícios\n",
    "df = generate_medical_data(100)\n",
    "\n",
    "# Salve o dataset em um arquivo CSV\n",
    "df.to_csv('faker/fake_medical.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de propriedades fictícias para o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Configurar a biblioteca Faker\n",
    "fake = Faker()\n",
    "\n",
    "def generate_real_estate_data(n):\n",
    "    \n",
    "    property_types = [\"Casa\", \"Apartamento\", \"Terreno\", \"Loft\", \"Chácara\", \"Condomínio\"]\n",
    "\n",
    "    # Gerar dados fictícios\n",
    "    property_ids = [i+1 for i in range(n)]\n",
    "    addresses = [fake.address().replace(\"\\n\", \", \") for _ in range(n)]\n",
    "    types = [fake.random_element(elements=property_types) for _ in range(n)]\n",
    "    bedrooms = [fake.random_int(min=1, max=6) for _ in range(n)]\n",
    "    bathrooms = [fake.random_int(min=1, max=4) for _ in range(n)]\n",
    "    area = [fake.random_int(min=40, max=500) for _ in range(n)]\n",
    "    prices = [round(random.uniform(50000, 2000000), 2) for _ in range(n)]\n",
    "    construction_dates = [fake.date_between_dates(date_start=pd.to_datetime(\"1990-01-01\"), date_end=pd.to_datetime(\"2023-01-01\")) for _ in range(n)]\n",
    "    garage = [fake.random_element(elements=[\"Sim\", \"Não\"]) for _ in range(n)]\n",
    "    descriptions = [fake.sentence(nb_words=10) for _ in range(n)]\n",
    "\n",
    "    # Criar DataFrame\n",
    "    data = {\n",
    "        \"ID da Propriedade\": property_ids,\n",
    "        \"Endereço\": addresses,\n",
    "        \"Tipo\": types,\n",
    "        \"Quartos\": bedrooms,\n",
    "        \"Banheiros\": bathrooms,\n",
    "        \"Área (m²)\": area,\n",
    "        \"Preço ($)\": prices,\n",
    "        \"Data de Construção\": construction_dates,\n",
    "        \"Garagem\": garage,\n",
    "        \"Descrição\": descriptions\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Gere um dataset com 100 linhas de dados fictícios\n",
    "df = generate_real_estate_data(100)\n",
    "print(df)\n",
    "\n",
    "# Salve o dataset em um arquivo CSV\n",
    "df.to_csv('faker/fake_real_state.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar dados fictícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Configurar a biblioteca Faker\n",
    "fake = Faker()\n",
    "\n",
    "def generate_retail_data(n):\n",
    "\n",
    "    sale_ids = [i+1 for i in range(n)]\n",
    "    client_names = [fake.name() for _ in range(n)]\n",
    "    products = [fake.bs() for _ in range(n)]  # Usando \"bs()\" como nome de produto genérico.\n",
    "    quantities = [fake.random_int(min=1, max=10) for _ in range(n)]\n",
    "    unit_prices = [round(random.uniform(1.99, 99.99), 2) for _ in range(n)]\n",
    "    total_values = [quantities[i] * unit_prices[i] for i in range(n)]\n",
    "    sale_dates = [fake.date_this_decade() for _ in range(n)]\n",
    "    payment_methods = [fake.random_element(elements=('Cartão de Crédito', 'Boleto', 'Débito', 'Dinheiro')) for _ in range(n)]\n",
    "    seller_names = [fake.first_name() for _ in range(n)]\n",
    "    stores = [fake.company() for _ in range(n)]\n",
    "    \n",
    "    # Criar DataFrame\n",
    "    data = {\n",
    "        \"ID da Venda\": sale_ids,\n",
    "        \"Nome do Cliente\": client_names,\n",
    "        \"Produto\": products,\n",
    "        \"Quantidade\": quantities,\n",
    "        \"Preço Unitário\": unit_prices,\n",
    "        \"Valor Total\": total_values,\n",
    "        \"Data da Venda\": sale_dates,\n",
    "        \"Método de Pagamento\": payment_methods,\n",
    "        \"Nome do Vendedor\": seller_names,\n",
    "        \"Loja\": stores\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Gere um dataset com 100 linhas de dados fictícios\n",
    "df = generate_retail_data(100)\n",
    "\n",
    "# Salve o dataset em um arquivo CSV\n",
    "df.to_csv('faker/fake_retail.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Configurar a biblioteca Faker\n",
    "fake = Faker()\n",
    "\n",
    "def generate_videogame_data(n):\n",
    "    # Gêneros e plataformas fictícios para o dataset\n",
    "    genres = [\"Ação\", \"Aventura\", \"RPG\", \"Esporte\", \"Estratégia\", \"Corrida\", \"Luta\", \"Simulação\"]\n",
    "    platforms = [\"PC\", \"PS5\", \"Xbox Series X\", \"Switch\", \"Mobile\"]\n",
    "\n",
    "    # Gerar dados fictícios\n",
    "    game_ids = [i+1 for i in range(n)]\n",
    "    game_titles = [fake.catch_phrase() for _ in range(n)]\n",
    "    game_genres = [fake.random_element(elements=genres) for _ in range(n)]\n",
    "    game_platforms = [fake.random_element(elements=platforms) for _ in range(n)]\n",
    "    release_years = [fake.random_int(min=2000, max=2023) for _ in range(n)]\n",
    "    prices = [round(random.uniform(10.99, 199.99), 2) for _ in range(n)]\n",
    "    ratings = [round(random.uniform(1, 10), 2) for _ in range(n)]\n",
    "    developers = [fake.company() for _ in range(n)]\n",
    "    descriptions = [fake.sentence(nb_words=10) for _ in range(n)]\n",
    "    stock = [fake.random_int(min=0, max=500) for _ in range(n)]\n",
    "\n",
    "    # Criar DataFrame\n",
    "    data = {\n",
    "        \"ID do Game\": game_ids,\n",
    "        \"Título\": game_titles,\n",
    "        \"Gênero\": game_genres,\n",
    "        \"Plataforma\": game_platforms,\n",
    "        \"Ano de Lançamento\": release_years,\n",
    "        \"Preço\": prices,\n",
    "        \"Avaliação\": ratings,\n",
    "        \"Estúdio\": developers,\n",
    "        \"Descrição\": descriptions,\n",
    "        \"Estoque\": stock\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Gere um dataset com 100 linhas de dados fictícios\n",
    "df = generate_videogame_data(100)\n",
    "\n",
    "# Salve o dataset em um arquivo CSV\n",
    "df.to_csv('fake_videogame.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from faker import Faker\n",
    "import random\n",
    "import csv\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Set the number of rows to generate\n",
    "num_rows = 100\n",
    "\n",
    "# Define the column headers\n",
    "headers = [\"date\", \"name\", \"age\", \"city\", \"state\", \n",
    "                          \"fare\", \"gender\", \"occupation\"]\n",
    "\n",
    "CITIES = [\n",
    "    \"New York\",\n",
    "    \"Los Angeles\",\n",
    "    \"Chicago\",\n",
    "    \"Houston\",\n",
    "    \"Phoenix\",\n",
    "    \"Philadelphia\",\n",
    "    \"San Antonio\",\n",
    "    \"San Diego\",\n",
    "    \"Dallas\",\n",
    "    \"San Jose\",\n",
    "    \"Austin\",\n",
    "    \"Jacksonville\",\n",
    "    \"Fort Worth\",\n",
    "    \"Columbus\",\n",
    "    \"San Francisco\",\n",
    "    \"Charlotte\",\n",
    "    \"Indianapolis\",\n",
    "    \"Seattle\",\n",
    "    \"Denver\",\n",
    "    \"Washington\",\n",
    "    \"Boston\",\n",
    "    \"Nashville\",\n",
    "    \"El Paso\",\n",
    "    \"Detroit\",\n",
    "    \"Memphis\",\n",
    "    \"Portland\",\n",
    "    \"Oklahoma City\",\n",
    "    \"Las Vegas\",\n",
    "    \"Louisville\",\n",
    "    \"Baltimore\",\n",
    "    \"Milwaukee\",\n",
    "    \"Albuquerque\",\n",
    "    \"Tucson\",\n",
    "    \"Fresno\",\n",
    "    \"Mesa\",\n",
    "    \"Sacramento\",\n",
    "    \"Atlanta\",\n",
    "    \"Kansas City\",\n",
    "    \"Colorado Springs\",\n",
    "    \"Miami\",\n",
    "    \"Raleigh\",\n",
    "    \"Omaha\",\n",
    "    \"Long Beach\",\n",
    "    \"Virginia Beach\",\n",
    "    \"Oakland\",\n",
    "    \"Minneapolis\",\n",
    "    \"Tulsa\",\n",
    "    \"Wichita\",\n",
    "    \"New Orleans\",\n",
    "    \"Arlington\",\n",
    "]\n",
    "\n",
    "STATES = [\n",
    "    \"Alabama\",\n",
    "    \"Alaska\",\n",
    "    \"Arizona\",\n",
    "    \"Arkansas\",\n",
    "    \"California\",\n",
    "    \"Colorado\",\n",
    "    \"Connecticut\",\n",
    "    \"Delaware\",\n",
    "    \"Florida\",\n",
    "    \"Georgia\",\n",
    "    \"Hawaii\",\n",
    "    \"Idaho\",\n",
    "    \"Illinois\",\n",
    "    \"Indiana\",\n",
    "    \"Iowa\",\n",
    "    \"Kansas\",\n",
    "    \"Kentucky\",\n",
    "    \"Louisiana\",\n",
    "    \"Maine\",\n",
    "    \"Maryland\",\n",
    "    \"Massachusetts\",\n",
    "    \"Michigan\",\n",
    "    \"Minnesota\",\n",
    "    \"Mississippi\",\n",
    "    \"Missouri\",\n",
    "    \"Montana\",\n",
    "    \"Nebraska\",\n",
    "    \"Nevada\",\n",
    "    \"New Hampshire\",\n",
    "    \"New Jersey\",\n",
    "    \"New Mexico\",\n",
    "    \"New York\",\n",
    "    \"North Carolina\",\n",
    "    \"North Dakota\",\n",
    "    \"Ohio\",\n",
    "    \"Oklahoma\",\n",
    "    \"Oregon\",\n",
    "    \"Pennsylvania\",\n",
    "    \"Rhode Island\",\n",
    "    \"South Carolina\",\n",
    "    \"South Dakota\",\n",
    "    \"Tennessee\",\n",
    "    \"Texas\",\n",
    "    \"Utah\",\n",
    "    \"Vermont\",\n",
    "    \"Virginia\",\n",
    "    \"Washington\",\n",
    "    \"West Virginia\",\n",
    "    \"Wisconsin\",\n",
    "    \"Wyoming\",\n",
    "]\n",
    "\n",
    "OCCUPATIONS = [\n",
    "    \"Software Engineer\",\n",
    "    \"Data Scientist\",\n",
    "    \"Teacher\",\n",
    "    \"Nurse\",\n",
    "    \"Doctor\",\n",
    "    \"Lawyer\",\n",
    "    \"Accountant\",\n",
    "    \"Sales Manager\",\n",
    "    \"Marketing Specialist\",\n",
    "    \"Writer\",\n",
    "    \"Chef\",\n",
    "    \"Electrician\",\n",
    "    \"Plumber\",\n",
    "    \"Mechanic\",\n",
    "    \"Architect\",\n",
    "    \"Artist\",\n",
    "    \"Musician\",\n",
    "    \"Pilot\",\n",
    "    \"Police Officer\",\n",
    "    \"Firefighter\",\n",
    "]\n",
    "\n",
    "# Open a new CSV file for writing\n",
    "with open(\"input.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Generate fake data and write to the CSV file\n",
    "    for i in range(num_rows):\n",
    "        # Generate a fake date between 2020 and 2023\n",
    "        date = fake.date_between_dates(\n",
    "            date_start=datetime.date(2020, 1, 1), date_end=datetime.date(2023, 12, 31)\n",
    "        )\n",
    "\n",
    "        # Generate a fake name\n",
    "        name = fake.name()\n",
    "\n",
    "        # Generate a random age between 18 and 80\n",
    "        age = random.randint(18, 80)\n",
    "\n",
    "        # Generate a fake city and state\n",
    "        city = random.choice(CITIES)\n",
    "        state = random.choice(STATES)\n",
    "\n",
    "        # Generate a random fare between 10 and 100\n",
    "        fare = round(random.uniform(10, 100), 2)\n",
    "\n",
    "        # Generate a random gender\n",
    "        gender = random.choice([\"Male\", \"Female\"])\n",
    "\n",
    "        # Generate a random occupation\n",
    "        occupation = random.choice(OCCUPATIONS)\n",
    "\n",
    "        # Write the data to the CSV file\n",
    "        writer.writerow([date, name, age, city, state, fare, gender, occupation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
